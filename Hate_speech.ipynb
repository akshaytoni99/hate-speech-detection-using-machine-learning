{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZFfPkC26NDcx"
   },
   "source": [
    "# Hate Speech Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4IVq4OS4NDc2",
    "outputId": "b375ce1b-a2b9-4834-c8d8-683086914162"
   },
   "outputs": [],
   "source": [
    "import pandas as panda\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import *\n",
    "import string\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn\n",
    "# from textstat.textstat import *\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import numpy as np\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer as VS\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "LGYa0YcXNDc5",
    "outputId": "83eed07c-6f02-4c8c-93ee-5a4a6c3cee05"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24778</th>\n",
       "      <td>25291</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>you's a muthaf***in lie &amp;#8220;@LifeAsKing: @2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24779</th>\n",
       "      <td>25292</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>you've gone and broke the wrong heart baby, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24780</th>\n",
       "      <td>25294</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>young buck wanna eat!!.. dat nigguh like I ain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24781</th>\n",
       "      <td>25295</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>youu got wild bitches tellin you lies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24782</th>\n",
       "      <td>25296</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>~~Ruffled | Ntac Eileen Dahlia - Beautiful col...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24783 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
       "0               0      3            0                   0        3      2   \n",
       "1               1      3            0                   3        0      1   \n",
       "2               2      3            0                   3        0      1   \n",
       "3               3      3            0                   2        1      1   \n",
       "4               4      6            0                   6        0      1   \n",
       "...           ...    ...          ...                 ...      ...    ...   \n",
       "24778       25291      3            0                   2        1      1   \n",
       "24779       25292      3            0                   1        2      2   \n",
       "24780       25294      3            0                   3        0      1   \n",
       "24781       25295      6            0                   6        0      1   \n",
       "24782       25296      3            0                   0        3      2   \n",
       "\n",
       "                                                   tweet  \n",
       "0      !!! RT @mayasolovely: As a woman you shouldn't...  \n",
       "1      !!!!! RT @mleew17: boy dats cold...tyga dwn ba...  \n",
       "2      !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...  \n",
       "3      !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...  \n",
       "4      !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...  \n",
       "...                                                  ...  \n",
       "24778  you's a muthaf***in lie &#8220;@LifeAsKing: @2...  \n",
       "24779  you've gone and broke the wrong heart baby, an...  \n",
       "24780  young buck wanna eat!!.. dat nigguh like I ain...  \n",
       "24781              youu got wild bitches tellin you lies  \n",
       "24782  ~~Ruffled | Ntac Eileen Dahlia - Beautiful col...  \n",
       "\n",
       "[24783 rows x 7 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = panda.read_csv(r'C:\\Users\\aksha\\Music\\project2\\HATESPEECH\\FINALCODE\\Dataset\\HateSpeechData.csv')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "HXAvmKNjNDc6"
   },
   "outputs": [],
   "source": [
    "# Adding text-length as a field in the dataset\n",
    "dataset['text length'] = dataset['tweet'].apply(len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "AH5x5uvfOU3a",
    "outputId": "71aaa105-9a41-4a53-dff8-17cd1c262423"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "      <th>text length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
       "0           0      3            0                   0        3      2   \n",
       "1           1      3            0                   3        0      1   \n",
       "2           2      3            0                   3        0      1   \n",
       "3           3      3            0                   2        1      1   \n",
       "4           4      6            0                   6        0      1   \n",
       "\n",
       "                                               tweet  text length  \n",
       "0  !!! RT @mayasolovely: As a woman you shouldn't...          140  \n",
       "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...           85  \n",
       "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...          120  \n",
       "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...           62  \n",
       "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...          137  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 242
    },
    "id": "2jbEkUGMNDc7",
    "outputId": "67a3f9fa-f1ab-495b-9eab-f88f4121119a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x1d57b40e1e0>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Basic visualization of data using histograms\n",
    "# FacetGrid- Multi-plot grid for plotting conditional relationships\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "graph = sns.FacetGrid(data=dataset, col='class')\n",
    "graph.map(plt.hist, 'text length', bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "id": "nF3OsgnZNDc9",
    "outputId": "a79b8d73-d4a1-4271-9e39-e08e472dc9e6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: title={'center': 'class = 2'}, xlabel='text length', ylabel='text length'>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Box-plot visvualization\n",
    "sns.boxplot(x='class', y='text length', data=dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "jYW8QyQrNDc_",
    "outputId": "c9d0fc15-adcb-4211-f9b7-e8a21e65b92c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: title={'center': 'class = 2'}, xlabel='text length', ylabel='text length'>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['class'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "sCO19ujbNDdA"
   },
   "outputs": [],
   "source": [
    "# collecting only the tweets from the csv file into a variable name tweet\n",
    "tweet=dataset.tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6uSMO1D8NDdA"
   },
   "source": [
    "## Preprocessing of the tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kDMzzVQN0dbM",
    "outputId": "fec52c40-5dc5-4f28-c2ae-5b5e71a6294c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\aksha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\aksha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# Download stopwords if not already done\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Initialize\n",
    "stopwords_list = stopwords.words(\"english\")\n",
    "other_exclusions = [\"#ff\", \"ff\", \"rt\"]\n",
    "stopwords_list.extend(other_exclusions)\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def preprocess(tweet):  \n",
    "    # Remove extra spaces\n",
    "    regex_pat = re.compile(r'\\s+')\n",
    "    tweet_space = tweet.str.replace(regex_pat, ' ', regex=True)\n",
    "\n",
    "    # Remove @mentions\n",
    "    regex_pat = re.compile(r'@[\\w\\-]+')\n",
    "    tweet_name = tweet_space.str.replace(regex_pat, '', regex=True)\n",
    "\n",
    "    # Remove URLs\n",
    "    url_pattern = re.compile(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F]{2}))+')\n",
    "    tweets = tweet_name.str.replace(url_pattern, '', regex=True)\n",
    "    \n",
    "    # Remove punctuation and numbers\n",
    "    punc_remove = tweets.str.replace(\"[^a-zA-Z]\", \" \", regex=True)\n",
    "    newtweet = punc_remove.str.replace(r'\\s+', ' ', regex=True)\n",
    "    newtweet = newtweet.str.replace(r'^\\s+|\\s+?$', '', regex=True)\n",
    "    newtweet = newtweet.str.replace(r'\\d+(\\.\\d+)?', 'numbr', regex=True)\n",
    "\n",
    "    # Convert to lowercase\n",
    "    tweet_lower = newtweet.str.lower()\n",
    "    \n",
    "    # Tokenizing\n",
    "    tokenized_tweet = tweet_lower.apply(lambda x: x.split())\n",
    "\n",
    "    # Remove stopwords\n",
    "    tokenized_tweet = tokenized_tweet.apply(lambda x: [item for item in x if item not in stopwords_list])\n",
    "\n",
    "    # Stemming\n",
    "    tokenized_tweet = tokenized_tweet.apply(lambda x: [stemmer.stem(i) for i in x])\n",
    "\n",
    "    # Rejoin tokens into a single string\n",
    "    tokenized_tweet = tokenized_tweet.apply(lambda x: ' '.join(x))\n",
    "    \n",
    "    return tokenized_tweet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               tweet  \\\n",
      "0  !!! RT @mayasolovely: As a woman you shouldn't...   \n",
      "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...   \n",
      "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...   \n",
      "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...   \n",
      "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...   \n",
      "5  !!!!!!!!!!!!!!!!!!\"@T_Madison_x: The shit just...   \n",
      "6  !!!!!!\"@__BrighterDays: I can not just sit up ...   \n",
      "7  !!!!&#8220;@selfiequeenbri: cause I'm tired of...   \n",
      "8  \" &amp; you might not get ya bitch back &amp; ...   \n",
      "9  \" @rhythmixx_ :hobbies include: fighting Maria...   \n",
      "\n",
      "                                    processed_tweets  \n",
      "0  woman complain clean hous amp man alway take t...  \n",
      "1  boy dat cold tyga dwn bad cuffin dat hoe st place  \n",
      "2         dawg ever fuck bitch start cri confus shit  \n",
      "3                                   look like tranni  \n",
      "4     shit hear might true might faker bitch told ya  \n",
      "5      shit blow claim faith somebodi still fuck hoe  \n",
      "6              sit hate anoth bitch got much shit go  \n",
      "7            caus tire big bitch come us skinni girl  \n",
      "8               amp might get ya bitch back amp that  \n",
      "9                    hobbi includ fight mariam bitch  \n"
     ]
    }
   ],
   "source": [
    "processed_tweets = preprocess(dataset['tweet'])\n",
    "dataset['processed_tweets'] = processed_tweets\n",
    "\n",
    "print(dataset[[\"tweet\", \"processed_tweets\"]].head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zX0VvmM4NDdC"
   },
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 380
    },
    "id": "F9beMcztNDdC",
    "outputId": "7f7fa315-9eaa-457b-fc35-a1a02baa65a3"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'wordcloud'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[100], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwordcloud\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m WordCloud\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Assuming `dataset['processed_tweets']` exists and is preprocessed properly\u001b[39;00m\n\u001b[0;32m      5\u001b[0m all_words \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([text \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprocessed_tweets\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'wordcloud'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# Assuming `dataset['processed_tweets']` exists and is preprocessed properly\n",
    "all_words = ' '.join([text for text in dataset['processed_tweets']])\n",
    "\n",
    "# Create and generate a word cloud image:\n",
    "wordcloud = WordCloud(width=800, height=500, random_state=21, max_font_size=110).generate(all_words)\n",
    "\n",
    "# Display the generated image:\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 380
    },
    "id": "CbT8hOqNNDdD",
    "outputId": "715b0312-aec3-42c3-d63d-ce0309430664"
   },
   "outputs": [],
   "source": [
    "# visualizing which of the word is most commonly used for hatred speech\n",
    "hatred_words = ' '.join([text for text in dataset['processed_tweets'][dataset['class'] == 0]])\n",
    "wordcloud = WordCloud(width=800, height=500,\n",
    "random_state=21, max_font_size=110).generate(hatred_words)\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 380
    },
    "id": "WK70eYzFNDdE",
    "outputId": "c84f515c-6721-4e2e-9d5f-4d9ba498c803"
   },
   "outputs": [],
   "source": [
    "# visualizing which of the word is most commonly used for offensive speech\n",
    "offensive_words = ' '.join([text for text in dataset['processed_tweets'][dataset['class'] == 1]])\n",
    "wordcloud = WordCloud(width=800, height=500,\n",
    "random_state=21, max_font_size=110).generate(offensive_words)\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining all the above stundents \n",
    "from tqdm import tqdm\n",
    "def preprocess_text(text_data):\n",
    "    preprocessed_text = []\n",
    "    # tqdm is for printing the status bar\n",
    "    for sentance in tqdm(text_data):\n",
    "        sent = decontracted(sentance)\n",
    "        sent = sent.replace('\\\\r', ' ')\n",
    "        sent = sent.replace('\\\\n', ' ')\n",
    "        sent = sent.replace('\\\\\"', ' ')\n",
    "        sent = re.sub('[^A-Za-z0-9]+', ' ', sent)\n",
    "        # https://gist.github.com/sebleier/554280\n",
    "        sent = ' '.join(e for e in sent.split() if e.lower() not in stopwords)\n",
    "        preprocessed_text.append(sent.lower().strip())\n",
    "    return preprocessed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def decontracted(phrase):\n",
    "    # specific\n",
    "    phrase = re.sub(r\"won't\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "\n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "stop_words.update([\"#ff\", \"ff\", \"rt\"])\n",
    "\n",
    "def decontracted(phrase):\n",
    "    phrase = re.sub(r\"won't\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can't\", \"cannot\", phrase)\n",
    "    phrase = re.sub(r\"n't\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"'m\", \" am\", phrase)\n",
    "    return phrase\n",
    "\n",
    "def preprocess_text(text_data):\n",
    "    preprocessed_text = []\n",
    "    for sentence in tqdm(text_data, desc=\"Preprocessing\"):\n",
    "        sent = decontracted(sentence)\n",
    "        sent = sent.replace('\\\\r', ' ')\n",
    "        sent = sent.replace('\\\\n', ' ')\n",
    "        sent = sent.replace('\\\\\"', ' ')\n",
    "        sent = re.sub(r'[^A-Za-z0-9]+', ' ', sent)\n",
    "        sent = ' '.join(e for e in sent.split() if e.lower() not in stop_words)\n",
    "        preprocessed_text.append(sent.lower().strip())\n",
    "    return preprocessed_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "preprocessed_text = preprocess_text(dataset['tweet'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"printing some random reviews\")\n",
    "print(9, preprocessed_text[9])\n",
    "print(34, preprocessed_text[34])\n",
    "print(147, preprocessed_text[149])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " y=np.array(dataset['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#Breaking into Train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(preprocessed_text, y, test_size=0.3,stratify=y ,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x7RTlPcpNDdE"
   },
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8YzGDVcsNDdE",
    "outputId": "def6ccb6-d1eb-4a8e-cf7b-e39971579d7c"
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "tfidf = TfidfVectorizer(ngram_range=(1,2), min_df=10)\n",
    "count_trans = tfidf.fit(X_train) # fit has to happen only on train data\n",
    "\n",
    "# Dump the file\n",
    "pickle.dump(tfidf, open(r\"C:\\Users\\aksha\\Music\\project2\\HATESPEECH\\FINALCODE\\FRONT END\\new_project\\tfidf.pkl\", \"wb\"))\n",
    "# Testing phase\n",
    "tfidf = pickle.load(open(r\"C:\\Users\\aksha\\Music\\project2\\HATESPEECH\\FINALCODE\\FRONT END\\new_project\\tfidf.pkl\", 'rb'))\n",
    "\n",
    "# we use the fitted CountVectorizer to convert the text to vector\n",
    "X_train_tfidf =tfidf.transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "#Normalize Data\n",
    "X_train_tfidf = preprocessing.normalize(X_train_tfidf)\n",
    "print(\"Train Data Size: \",X_train_tfidf.shape)\n",
    "\n",
    "#Normalize Data\n",
    "X_test_tfidf = preprocessing.normalize(X_test_tfidf)\n",
    "print(\"Test Data Size: \",X_test_tfidf.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_aC3BD0jNDdF"
   },
   "source": [
    "### Running various model Using TFIDF without additional features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AKFq-ltqNDdG",
    "outputId": "a4c1cdf8-a544-4e1a-dfbf-f6b1cac95aae"
   },
   "outputs": [],
   "source": [
    "rf=RandomForestClassifier()\n",
    "rf.fit(X_train_tfidf,y_train)\n",
    "filename = r'C:\\Users\\aksha\\Music\\project2\\HATESPEECH\\FINALCODE\\FRONT END\\new_project\\rf_hatespeech.pkl'\n",
    "pickle.dump(rf, open(filename, 'wb'))\n",
    "y_preds = rf.predict(X_test_tfidf)\n",
    "acc1=accuracy_score(y_test,y_preds)\n",
    "report = classification_report( y_test, y_preds )\n",
    "print(report)\n",
    "print(\"Random Forest, Accuracy Score:\",acc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "4mRhc1-i3cwE",
    "outputId": "46cdbc16-44d1-4d45-b98b-d4a96e57655c"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "class_names =['Hate','Offensive','Neither']\n",
    "df_heatmap = pd.DataFrame(confusion_matrix(y_test, y_preds.round()), index=class_names, columns=class_names )\n",
    "fig = plt.figure( )\n",
    "heatmap = sns.heatmap(df_heatmap, annot=True, fmt=\"d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xOR_CtIzNDdH",
    "outputId": "b996ce6e-fb97-41cc-9003-96248f9a2f0a"
   },
   "outputs": [],
   "source": [
    "support =LinearSVC(random_state=20)\n",
    "support.fit(X_train_tfidf,y_train)\n",
    "filename = r'C:\\Users\\aksha\\Music\\project2\\HATESPEECH\\FINALCODE\\FRONT END\\new_project\\svm_hatespeech.pkl'\n",
    "pickle.dump(rf, open(filename, 'wb'))\n",
    "acc3=accuracy_score(y_test,y_preds)\n",
    "report = classification_report( y_test, y_preds )\n",
    "print(report)\n",
    "print(\"SVM, Accuracy Score:\" , acc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "_DM7bLFG3uqD",
    "outputId": "2324e63b-c115-407b-b342-d143ece663d2"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "class_names =['Hate','Offensive','Neither']\n",
    "df_heatmap = pd.DataFrame(confusion_matrix(y_test, y_preds.round()), index=class_names, columns=class_names )\n",
    "fig = plt.figure( )\n",
    "heatmap = sns.heatmap(df_heatmap, annot=True, fmt=\"d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "NBYCzjyaNDdH",
    "outputId": "79f1f5cb-a289-4dcd-a3f5-64b971f5289b"
   },
   "outputs": [],
   "source": [
    "objects = ('RandomForest', 'SVM')\n",
    "y_pos = np.arange(len(objects))\n",
    "performance = [acc1,acc3]\n",
    "plt.bar(y_pos, performance, align='center', alpha=0.5)\n",
    "plt.xticks(y_pos, objects)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Algorithm Comparision for F1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Hate_speech[final].ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
